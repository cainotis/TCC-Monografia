%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101

%% ------------------------------------------------------------------------- %%

\chapter{Deep Q-Network}
\label{cap:dqn}

\section{O que é Deep Q-Network?}
\label{sec:o-que-e-dqn}

\enlargethispage{.5\baselineskip}
DQN ou \textit{Deep Q-Network}\index{Deep Q-Network} é um algoritmo desenvolvido em 2015 pela DeepMind para aprendizado por reforço ~\citep{Human-level-control}. O DQN é um dos primeiros algoritmos a ter sucesso em adicionar deep neural network à métodos de aprendizagem por reforço, visto que, ele é uma variação do \textit{Q-Learning}, um clássico algoritmo de aprendizado por reforço, cujos \textit{Q-Values} são, ao contrário do método clássico que armazena os valores em uma tabela, aproximados por uma deep network. As tentativas anteriores de criar um algoritmo que une o \textit{deep learning} e o aprendizado por reforço falharam em virtude dos métodos de deep learning a sofrer \textit{overfitting} o que deixa o sistema instável, contudo a equipe de pesquisadores do DeepMind foi capaz de de resolver esse problema ao remover a correlação da sequência de observação com a aleatorização dos dados e ao reduzir a correlação com valor alvo com atualização deles de forma periódica.

\section{Q-learning}
\label{sec:q-learning}

\enlargethispage{.5\baselineskip}
WIP
